{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65017430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is Newton?\n",
      "Answer: Sir Isaac Newton was a very smart scientist who lived a long time ago. He came up with three important rules about how things move, called Newton's Laws of Motion. These rules explain how objects stay still, move, and how forces like pushing and pulling affect them. Thanks to Newton's laws, we know a lot more about how things work in the world.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sir Isaac Newton was a very smart scientist who lived a long time ago. He came up with three important rules about how things move, called Newton's Laws of Motion. These rules explain how objects stay still, move, and how forces like pushing and pulling affect them. Thanks to Newton's laws, we know a lot more about how things work in the world.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from operator import itemgetter \n",
    "load_dotenv()\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "def model_embeddings_vectordatabase(pdf,key=\"OPENAI_API_KEY\"):\n",
    "    api_key = os.getenv(key)\n",
    "    Model = \"gpt-3.5-turbo\"   #mistral or GPT with api_key\n",
    "    #Model = \"llama2\" #Open-source model\n",
    "    \n",
    "    #declaring the model and embeddings\n",
    "    if Model.startswith(\"gpt\"):\n",
    "        model = ChatOpenAI(api_key=api_key,model=Model)\n",
    "        embeddings=OpenAIEmbeddings()\n",
    "    else:\n",
    "        model = Ollama(base_url='http://host.docker.internal:11434',model='llama2')\n",
    "        embeddings=OllamaEmbeddings(base_url='http://host.docker.internal:11434',model=\"llama2\")\n",
    "    \n",
    "    #define pages\n",
    "    loader = PyPDFLoader(pdf)\n",
    "    pages = loader.load_and_split()\n",
    "\n",
    "    #vectorstore\n",
    "    vectorstore=DocArrayInMemorySearch.from_documents(pages,embedding=embeddings)\n",
    "    \n",
    "    return vectorstore, model\n",
    "\n",
    " \n",
    "\n",
    "def RAG_inference(question, vectorstore, model,key=\"OPENAI_API_KEY\"):\n",
    "    \n",
    "    #parser declaration\n",
    "    parser=StrOutputParser()\n",
    "    \n",
    "    #defining a template for prompt\n",
    "    template = \"\"\"\n",
    "Answer the question in detial based on the context given below. The answer must cater to elementary school students. If you cannot find the answer from the context or if \n",
    "the context does not exist, Reply \"NULL\". \n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "    #prompt declaration\n",
    "    prompt=PromptTemplate.from_template(template)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    #Model pipeline\n",
    "    chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\")|retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    |prompt\n",
    "    |model\n",
    "    |parser\n",
    "\n",
    ")\n",
    "    Questions = [\n",
    "    question\n",
    "    ]\n",
    "    for question in Questions:\n",
    "        print(f\"Question:{question}\")\n",
    "        answer= chain.invoke({'question':question})\n",
    "        print(f\"Answer: {answer}\")\n",
    "        \n",
    "    return answer\n",
    "\n",
    "question=\" Who is Newton?\"\n",
    "chapter_path=r'C:\\Users\\saaij\\OneDrive - UCB-O365\\01. Study\\04. Hackathon and Competitions\\05. UC Berkely Hackathon 06-22-2024\\02. Hacking\\Final_Repo_2\\calhacks_narration_learning\\Niranjan Files\\pdfs\\Newtons_laws_NASA.pdf'\n",
    "\n",
    "vectorstore, model = model_embeddings_vectordatabase(chapter_path)   \n",
    "RAG_inference(question,vectorstore, model)   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895cbed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
